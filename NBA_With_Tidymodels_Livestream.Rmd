---
title: "NBA with Tidymodels"
author: "Michael Mullarkey"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
geometry: margin=0.50in
---

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
## setting working directory
opts_knit$set(root.dir = "/nba_tidymodels") ## Will need to change across computers
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, include = FALSE)

```

```{r}

## Create vector of packages we need for these analyses

packages <- c("tidymodels","readr","broom.mixed","rstanarm","tidyverse")

## Now write function to load each of these packages: Under construction

# map(packages,~{
#   .x <- enquo(.x)
#   if(!require(.x)){install.packages(.x)}
# library(.x)
# })

if(!require(tidymodels)){install.packages('tidymodels')}
library(tidymodels)
if(!require(readr)){install.packages('readr')}
library(readr)
if(!require(broom.mixed)){install.packages('broom.mixed')}
library(broom.mixed)
if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)
if(!require(nycflights13)){install.packages('nycflights13')}
library(nycflights13)
if(!require(skimr)){install.packages('skimr')}
library(skimr)
if(!require(modeldata)){install.packages('modeldata')}
library(modeldata)
if(!require(ranger)){install.packages('ranger')}
library(ranger)
if(!require(vip)){install.packages('vip')}
library(vip)
if(!require(gt)){install.packages('gt')}
library(gt)
if(!require(ggthemes)){install.packages('ggthemes')}
library(ggthemes)
if(!require(xgboost)){install.packages('xgboost')}
library(xgboost)
if(!require(keras)){install.packages('keras')}
library(keras)
if(!require(furrr)){install.packages('furrr')}
library(furrr)
if(!require(kernlab)){install.packages('kernlab')}
library(kernlab)
if(!require(mlbench)){install.packages('mlbench')}
library(mlbench)
if(!require(scales)){install.packages('scales')}
library(scales)
if(!require(tidyposterior)){install.packages('tidyposterior')}
library(tidyposterior)
if(!require(rstanarm)){install.packages('rstanarm')}
library(rstanarm)
if(!require(tictoc)){install.packages('tictoc')}
library(tictoc)
# library(devtools)
# devtools::install_github("abresler/nbastatR")
library(nbastatR)
if(!require(heatmaply)){install.packages('heatmaply')}
library(heatmaply)
if(!require(ggmosaic)){install.packages('ggmosaic')}
library(ggmosaic)
if(!require(splines)){install.packages('splines')}
library(splines)
if(!require(doMC)){install.packages('doMC')}
library(doMC)
if(!require(glue)){install.packages('glue')}
library(glue)
if(!require(stacks)){install.packages('stacks')}
library(stacks)
if(!require(future)){install.packages('future')}
library(future)
if(!require(janitor)){install.packages('janitor')}
library(janitor)
if(!require(future)){install.packages('future')}
library(future)
if(!require(reticulate)){install.packages('reticulate')}
library(reticulate)
if(!require(tensorflow)){install.packages('tensorflow')}
library(tensorflow)
if(!require(furrr)){install.packages('furrr')}
library(furrr)
if(!require(GGally)){install.packages('GGally')}
library(GGally)
if(!require(torch)){install.packages('torch')}
library(torch)
if(!require(tabnet)){install.packages('tabnet')}
library(tabnet)
if(!require(finetune)){install.packages('finetune')}
library(finetune)
if(!require(embed)){install.packages('embed')}
library(embed)


packages <- c("ggplot2", "dplyr", "lavaan", "plyr", "cowplot", "rmarkdown", 
              "readr", "caTools", "bitops", "heatmaply")

if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}

```

```{r setting up cores}

## Let's set our number of cores for this document

registerDoMC(cores = 7)

```

```{r reading in the data for one season}

tic()
plan(multisession)
all_bref_stats <- bref_players_stats(seasons = 2000:2019, tables = c("advanced", "totals"), widen = TRUE, assign_to_environment = FALSE)
toc()

```

```{r cleaning up twenty years of NBA data}

glimpse(all_bref_stats)

all_bref_stats_clean_names <- all_bref_stats %>% 
  janitor::clean_names()

glimpse(all_bref_stats_clean_names)

```

```{r starting to calculate next season true shooting percentage}

## First we need to figure out how many true shooting attempts

all_bref_stats_clean_names_with_true_shot_attempts <- all_bref_stats_clean_names %>% 
  mutate(true_shot_attempts = fga_totals + fta_totals)

all_bref_stats_clean_names_with_true_shot_attempts %>% 
  group_by(slug_season) %>% 
  summarise(mean_true_shot_attempts = mean(true_shot_attempts, na.rm = T))

all_bref_stats_clean_names_with_true_shot_attempts %>% 
  group_by(slug_season) %>% 
  summarise(median_true_shot_attempts = median(true_shot_attempts, na.rm = T))

all_bref_stats_clean_names_with_true_shot_attempts %>% 
  na.omit() %>% 
  ggplot(aes(x = true_shot_attempts)) +
  labs(x = "Number of True Shot Attempts") +
  geom_histogram(alpha = 0.7)

```

```{r how many true shot attempts are needed before true shooting percentage stabilizes}

all_bref_stats_clean_names_with_true_shot_attempts %>% 
  na.omit() %>% 
  ggplot(aes(x = true_shot_attempts, y = pct_true_shooting)) +
  geom_point(alpha = 0.2, position = "jitter") +
  geom_vline(xintercept = 200, color = "red")

## Let's see how many folks would stay in the data if we kept it to seasons with at least 500/200 true shot attempts

all_bref_stats_high_volume <- all_bref_stats_clean_names_with_true_shot_attempts %>% 
  filter(true_shot_attempts >= 200) %>% 
  print()

glimpse(all_bref_stats_high_volume)

```

```{r creating functions to put back to back seasons together into one dataframe}

## Do it once first

all_stats_2016 <- all_bref_stats_high_volume %>% 
  filter(year_season == 2017) %>% 
  print()

true_shooting_2017 <- all_bref_stats_high_volume %>% 
  filter(year_season == 2018) %>% 
  dplyr::select(slug_player_bref, ts_next_season = pct_true_shooting) %>% 
  print()

predicting_2017_ts_with_2016 <- all_stats_2016 %>% 
  left_join(true_shooting_2017, by = "slug_player_bref") %>% 
  print()

## Ok, writing a function, what variables would I need to input to do this programmatically

create_next_season_ts_df <- function(.data, year_1, year_2){
  
  all_stats_first_year <- .data %>% 
  filter(year_season == {{year_1}})

true_shooting_next_year <- .data %>% 
  filter(year_season == {{year_2}}) %>% 
  dplyr::select(slug_player_bref, ts_next_season = pct_true_shooting)

predicting_next_year_ts_with_previous_year <- all_stats_first_year %>% 
  left_join(true_shooting_next_year, by = "slug_player_bref")
  
}

test_df <- all_bref_stats_high_volume %>% 
  create_next_season_ts_df(year_1 = 2017, year_2 = 2018) %>%
  print()

## Let's test that the non-function version and the function version are the same

diffdf::diffdf(predicting_2017_ts_with_2016, test_df)

```

```{r using map function to create dataframes}

## Create year ones and year twos

year_ones <- all_bref_stats_high_volume %>% 
  dplyr::select(year_season) %>% 
  distinct() %>% 
  slice(-20) %>% 
  deframe()

year_twos <- all_bref_stats_high_volume %>% 
  dplyr::select(year_season) %>% 
  distinct() %>% 
  slice(-1) %>% 
  deframe()

all_seasons_predictive_df <- map2_dfr(.x = year_ones,.y = year_twos, ~{
  
  all_bref_stats_high_volume %>% 
  create_next_season_ts_df(year_1 = .x, year_2 = .y) 
  
})

all_seasons_predictive_df %>% 
  group_by(slug_season) %>% 
  tally()

```
```{r looking at missing data in our outcome variable}

all_seasons_predictive_df_drop_nas <- all_seasons_predictive_df %>% 
  filter(!is.na(ts_next_season))

all_seasons_predictive_df_drop_nas %>% 
  tally()

```

```{r creating scatter plot of outcome variable}

all_seasons_predictive_df_drop_nas %>% 
  ggplot(aes(x = pct_true_shooting, y = ts_next_season)) +
  geom_point(alpha = 0.2, position = "jitter") +
  geom_text(aes(label=ifelse(ts_next_season > 0.70 | ts_next_season < 0.35, as.character(name_player),'')), size = 2.5, nudge_x = 0.01, nudge_y = 0.01, check_overlap = F)

```

```{r feature engineering}

glimpse(all_seasons_predictive_df_drop_nas)

# all_in_one_vars_non_tidy <- c(all_seasons_predictive_df_drop_nas$ratio_per, all_seasons_predictive_df_drop_nas$ratio_bpm, all_seasons_predictive_df_drop_nas$ratio_ws, all_seasons_predictive_df_drop_nas$ratio_ws)
# 
# temp_p_max <- pmax(all_in_one_vars_non_tidy)
# length(temp_p_max)
# 
# nrow(all_seasons_predictive_df_drop_nas)*4
# 
# temp_max <- max(all_in_one_vars_non_tidy)
# length(temp_max)
# 
# nrow(all_seasons_predictive_df_drop_nas)*4

```

```{r}

## Code trying to create a max all in one stat feature, not currently working, have tried tunneling in the vars argument, but even if that's not used (for example, in current code) the function does not run. Might be worth checking up on the different types of rowwise syntax to see if I'm messing up something relatively straightforward

# all_in_one_vars <- c("ratio_per", "ratio_bpm", "ratio_ws", "ratio_ws")
# 
# create_max_all_in_one_stat <- function(.data, vars){
#   
#   .data <- .data %>% 
#     dplyr::select(contains("fga")) %>% 
#     rowwise() %>% 
#     mutate(c_across(everything(), ~pmax(.x)))
#            max_all_in_one_stat = case_when(
# 
#            max_all_in_one_stat_value == ratio_per  ~ "ratio_per",
#            max_all_in_one_stat_value == ratio_bpm  ~ "ratio_bpm",
#            max_all_in_one_stat_value == ratio_vorp  ~ "ratio_vorp",
#            max_all_in_one_stat_value == ratio_ws  ~ "ratio_ws"
# 
# 
# 
#          ))
#   
# }

all_seasons_predictive_df_drop_nas_feat_engin <- all_seasons_predictive_df_drop_nas %>% 
  mutate(ft_rate_fg2a = fta_totals/fg2a_totals,
         ft_rate_fg3a = fta_totals/fg3a_totals,
         ft_make_fg2a = ftm_totals/fg2a_totals,
         ft_make_fg3a = ftm_totals/fg3a_totals,
         ft_rate_fg2m = fta_totals/fg2m_totals,
         ft_rate_fg3m = fta_totals/fg3m_totals,
         ft_make_fg2m = ftm_totals/fg2m_totals,
         ft_make_fg3m = ftm_totals/fg3m_totals,
         pct_ts_usg = pct_true_shooting * pct_usg,
         pct_ts_usg_ratio = pct_true_shooting/pct_usg,
         above_average_shooter = factor(if_else(pct_true_shooting > 0.55, "Yes", "No")))

glimpse(all_seasons_predictive_df_drop_nas_feat_engin)

```


```{r splitting into training and testing sets}

set.seed(33)
nba_data_split <- initial_split(all_seasons_predictive_df_drop_nas_feat_engin, prop = 4/5, strata = ts_next_season)

train_nba_data <- training(nba_data_split)
test_nba_data <- testing(nba_data_split)

```

```{r}

nba_ts_predictors <- train_nba_data %>% 
  dplyr::select(is.numeric, -ts_next_season) %>% 
  names()

map(nba_ts_predictors, ~{
  
  train_nba_data %>% 
    ggplot(aes(x = .data[[.x]])) +
    geom_density(alpha = 0.2)
  
})

## We'll need to Box-Cox transformation because a lot of the predictor variables aren't symmetrical

```

```{r plotting correlations between predictors and outcome}

map(nba_ts_predictors, ~{
  
  train_nba_data %>% 
    ggplot(aes(x = .data[[.x]], y = ts_next_season)) +
    geom_point(alpha = 0.2, postion = "jitter") +
    geom_smooth(method = lm, formula = y ~ x, se = FALSE, col = "red") +
    labs(y = "True Shooting Percentage Next Season")
  
})

```

```{r}

## Creating preprocessing recipe

train_nba_data_updated <- train_nba_data %>%
  mutate(across(
    is.character,
    as.factor
  )) %>% 
  dplyr::select(-slug_player_season,-slug_player_bref,-slug_teams_bref) %>% 
  mutate(year_season = as.factor(year_season))

train_nba_data %>% 
  dplyr::select(contains("slug")) %>% 
  print()

glimpse(train_nba_data_updated)

nba_ts_recipe <- 
  recipe(ts_next_season ~ ., data = train_nba_data_updated) %>% 
  update_role(name_player, new_role = "id_variable") %>% 
  step_rm(contains("slug"), contains("url")) %>%
  step_dummy(all_nominal(), -has_role("id_variable")) %>% 
  step_knnimpute(all_numeric(),-all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_BoxCox(all_numeric(), -all_outcomes()) %>% 
  step_nzv(all_predictors(), -all_outcomes()) #%>% 
  #step_pca(all_numeric(), -all_outcomes(), threshold = 0.95)

summary(nba_ts_recipe)

## Creating model

el_net_mod <- linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine("glmnet")

## Put model and recipe into a workflow

nba_ts_wf <-
  workflow() %>% 
  add_model(el_net_mod) %>% 
  add_recipe(nba_ts_recipe)

## Double checking our tuning parameters

el_net_set <- parameters(nba_ts_wf)

## Let's create a baseline model to compare against

## Create linear reg model

linear_reg_mod <- linear_reg() %>% 
  set_engine("lm")

nba_ts_baseline_wf <-
  workflow() %>% 
  add_model(linear_reg_mod) %>% 
  add_formula(ts_next_season ~ pct_true_shooting)


```

```{r}

set.seed(33)
folds_nba_ts <- vfold_cv(train_nba_data_updated, v = 5, repeats = 5, strata = ts_next_season)

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
nba_ts_rs <-
  nba_ts_wf %>% 
  tune_bayes(
    resamples = folds_nba_ts,
    param_info = el_net_set,
    initial = 5,
    iter = 20,
    metrics = metric_set(rmse),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )
toc()

```

```{r}

best_el_net_hyp <- nba_ts_rs %>% 
  select_best("rmse")

final_el_net_nba_ts_wf <-
  nba_ts_wf %>% 
  finalize_workflow(best_el_net_hyp)

tic()
set.seed(33)
el_net_fit_rs_final <-
  final_el_net_nba_ts_wf %>% 
  fit_resamples(folds_nba_ts, control = keep_pred)
toc()

el_net_fit_rs_final %>% 
  collect_metrics(summarize = T)

collected_predictions <- collect_predictions(el_net_fit_rs_final, summarize = TRUE)

```


```{r seeing who the best and worst predictions are for}

biggest_misses_el_net <- collected_predictions %>% 
  mutate(residual = ts_next_season - .pred) %>% 
  arrange(desc(abs(residual))) %>% 
  slice(1:10) %>% 
  dplyr::select(ts_next_season, .pred, residual, .row)

train_nba_data_updated %>% 
  slice(row = biggest_misses_el_net$.row) %>% 
  dplyr::select(name_player) %>% 
  bind_cols(biggest_misses_el_net) %>% 
  dplyr::select(-.row)

most_accurate_el_net <- collected_predictions %>% 
  mutate(residual = ts_next_season - .pred) %>% 
  arrange(abs(residual)) %>% 
  slice(1:10) %>% 
  dplyr::select(ts_next_season, .pred, residual, .row)

train_nba_data_updated %>% 
  slice(row = most_accurate_el_net$.row) %>% 
  dplyr::select(name_player) %>% 
  bind_cols(most_accurate_el_net) %>% 
  dplyr::select(-.row)

```

```{r}

collected_predictions %>% 
  ggplot(aes(x = .pred, y = ts_next_season)) +
  geom_point(alpha = 0.2, position = "jitter")

```
```{r running a baseline model to compare against}

tic()
set.seed(33)
baseline_mod_fit_rs_final <-
  nba_ts_baseline_wf %>% 
  fit_resamples(folds_nba_ts, control = keep_pred)
toc()

baseline_mod_fit_rs_final %>% 
  collect_metrics(summarize = T)

collected_predictions <- collect_predictions(baseline_mod_fit_rs_final, summarize = TRUE)

```

```{r}

## A difference on the scale of 0.14%, so if you were that much better on average across each of the players on your team, how much better would you be at forecasting your team's point total?

train_nba_data_updated %>% 
  summarise(median = median(true_shot_attempts))

## Across the median number of shots, how many would we expect an average shooter to make?

745 * 0.55

## Let's say we knew that our players could make the % more that we can predict based on this data

745 * 0.564

## How many points is that across players on a team?

10 * 12 * 2

## How many points is that per game

240/82

```

```{r testing tabnet to see if we can improve our predictions}

## Tabnet tutorial https://blogs.rstudio.com/ai/posts/2021-02-11-tabnet/

torch_tensor(1)

set.seed(33)
torch_manual_seed(33)

tabnet_mod <- tabnet(epochs = 30) %>% 
  set_engine("torch", verbose = TRUE) %>% 
  set_mode("regression")

nnet_wf <- workflow() %>% 
  add_model(tabnet_mod) %>% 
  add_recipe(nba_ts_recipe)

tic()
fitted_model <- nnet_wf %>% 
  fit(train_nba_data_updated)
toc()


```


```{r getting fitted model}

preds <- train_nba_data_updated %>% 
  dplyr::select(ts_next_season, name_player) %>% 
  bind_cols(predict(fitted_model, train_nba_data_updated))

yardstick::rmse(preds, truth = ts_next_season, .pred)

## Can look into this code for doing cross-validation with tabnet (will start at ~the correct time) https://youtu.be/GuboAGHDgas?t=2904

```


```{r variable level feature importance}

fit <- pull_workflow_fit(fitted_model)
vip(fit) + theme_minimal()

```


```{r biggest misses and most accurate predictions for the neural network tabnet}

biggest_misses_nnet <- preds %>% 
  mutate(residual = ts_next_season - .pred) %>% 
  arrange(desc(abs(residual))) %>% 
  slice(1:10) %>% 
  dplyr::select(name_player, ts_next_season, .pred, residual) %>% 
  print()

most_accurate_nnet <- preds %>% 
  mutate(residual = ts_next_season - .pred) %>% 
  arrange(abs(residual)) %>% 
  slice(1:10) %>% 
  dplyr::select(name_player, ts_next_season, .pred, residual) %>% 
  print()

preds %>% 
  filter(name_player == "Speedy Claxton") %>% 
  mutate(residual = ts_next_season - .pred)

```


```{r observation level feature importance ie player level feature importance}

## Under construction

# ex_fit <- tabnet_explain(fit$fit, train_nba_data_updated)
# 
# ex_fit$M_explain %>%
#   mutate(observation = row_number()) %>%
#   pivot_longer(-observation, names_to = "variable", values_to = "m_agg") %>%
#   ggplot(aes(x = observation, y = variable, fill = m_agg)) +
#   geom_tile() +
#   theme_minimal() + 
#   scale_fill_viridis_c()


```
```{r what if we just do a supervised umap recipe instead}

rec_nba_ts_umap <- recipe(ts_next_season ~ ., data = train_nba_data_updated) %>% 
  update_role(name_player, new_role = "id_variable") %>% 
  step_rm(contains("slug"), contains("url")) %>%
  step_feature_hash(all_nominal(), -has_role("id_variable"), num_hash = 15) %>% 
  step_knnimpute(all_predictors(),-all_outcomes()) %>% 
  step_normalize(all_predictors(), -all_outcomes()) %>% 
  step_BoxCox(all_numeric(), -all_outcomes()) %>% 
  step_nzv(all_predictors(), -all_outcomes()) %>% 
  step_umap(all_predictors(), outcome = vars(ts_next_season), num_comp = 20)

# Ahh, it looks like I have to have tensor_flow loaded in order to do hashing and/or umap (I think the hashing?)

rec_nba_ts_umap %>% prep %>% juice()

rf_mod <- rand_forest() %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("regression")

nba_ts_umap_wf <-
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(rec_nba_ts_umap)

tic()
set.seed(33)
rf_umap_fit_rs_final <-
  nba_ts_umap_wf %>% 
  fit_resamples(folds_nba_ts, control = keep_pred)
toc()

rf_umap_fit_rs_final$.notes

rf_umap_fit_rs_final %>% 
  collect_metrics(summarize = T)

collected_predictions <- collect_predictions(rf_umap_fit_rs_final, summarize = TRUE)

```































```{r}

predicting_2017_ts_with_2016 %>% 
  dplyr::select(pct_true_shooting, ts_next_season) %>% 
  tally()

predicting_2017_ts_with_2016 %>% 
  filter(is.na(ts_next_season)) %>% 
  tally()


```









```{r}


bref_ts_2018 <- all_bref_stats_clean_names %>% 
  filter(year_season == 2018) %>% 
  dplyr::select(next_season_ts = pct_true_shooting, slug_player_bref)

bref_all_stats_2017_2018 <- all_bref_stats_clean_names %>% 
  filter(year_season == 2017) %>% 
  left_join(bref_ts_2018, by = "slug_player_bref")

glimpse(bref_all_stats_2017_2018)
  

```


```{r}

## Getting summary statistics, comparing the mean and standard deviation I'm guessing the distributions are really right-skewed

bref_all_stats_2017_2018 %>% 
  dplyr::select(fg3a_totals, fg2a_totals, fta_totals) %>% 
  summarise(across(
    everything(),
    .fns = list(mean = mean, sd = sd)))

## Setting up for mapping over ggplot for histogram

for_hist_plotting <- bref_all_stats_2017_2018 %>% 
  dplyr::select(fg3a_totals, fg2a_totals, fta_totals) %>% 
  names()

## Mapping across ggplot histogram

map(for_hist_plotting, ~{
  
  bref_all_stats_2017_2018 %>% 
    ggplot(aes(x = .data[[.x]])) +
    geom_density(alpha = 0.2)
  
})

## Looking at the median which we'll use as a cutoff

bref_all_stats_2017_2018 %>% 
  dplyr::select(fg3a_totals, fg2a_totals, fta_totals) %>% 
  summarise(across(
    everything(),
    .fns = list(median = median)))
  

```

```{r}

## Filtering down to high volume shooters

bref_all_stats_2017_2018_high_volume <- bref_all_stats_2017_2018 %>% 
  filter(fg2a_totals >= 114 & fta_totals >= 38)

## Filtering out players without an outcome the following season

bref_all_stats_2017_2018_complete <- bref_all_stats_2017_2018_high_volume %>% 
  filter(!is.na(next_season_ts)) %>% 
  print()

```

```{r}

## Split into training and testing data
set.seed(33)
live_code_nba_initial_split <- initial_split(bref_all_stats_2017_2018_complete, prop =3/4, strata = next_season_ts)

nba_train <- training(live_code_nba_initial_split)

nba_test <- testing(live_code_nba_initial_split)

```

```{r}

## Scatterplot of true shooting percentage the following season with true shooting percentage this season on the x-axis

nba_train %>% 
  na.omit() %>% 
  ggplot(aes(x = pct_true_shooting, y = next_season_ts)) +
  geom_point(alpha = 0.2, position = "jitter") +
  geom_text(aes(label=ifelse(next_season_ts > .67 | next_season_ts < 0.40,as.character(name_player), '')))
  

```

```{r}

## Setting up for mapping over ggplot for histogram

for_hist_plotting <- nba_train %>% 
  dplyr::select(is.numeric, -year_season, -id_player_nba) %>% 
  names()

## Mapping across ggplot histogram

map(for_hist_plotting, ~{
  
  nba_train %>% 
    ggplot(aes(x = .data[[.x]])) +
    geom_density(alpha = 0.2)
  
})

## Looks like we should do some Box Cox transformations of the numeric predictors

```

```{r}

## Looking at correlations between numeric predictors and outcome

# Do it once

nba_train %>% 
  ggplot(aes(x = pct_true_shooting, y =  next_season_ts)) +
  geom_point(alpha = 0.2, position = "jitter") +
  geom_smooth(method = lm, formula = y ~ x, se = FALSE, col = "red") +
  labs(y = "True Shooting Percentage Next Season")

# Write a function

for_cor_plotting <- nba_train %>% 
  dplyr::select(is.numeric, -year_season, -id_player_nba) %>% 
  names()

map(for_cor_plotting, ~{
  
  nba_train %>% 
  ggplot(aes(x = .data[[.x]], y =  next_season_ts)) +
  geom_point(alpha = 0.2, position = "jitter") +
  geom_smooth(method = lm, formula = y ~ x, se = FALSE, col = "red") +
  labs(y = "True Shooting Percentage Next Season")
  
})

```

```{r}

## looking at correlations between predictors

cor_mat <- nba_train %>% 
  dplyr::select(is.numeric, -year_season, -id_player_nba, -count_teams_player_season, -count_teams_player_season_totals, next_season_ts) %>%
  cor()

cor_map <-
  heatmaply_cor(
    cor_mat,
    symm = TRUE,
    cexRow = .0001,
    cexCol = .0001,
    branches_lwd = .1
  )
cor_map

## Should we do a pca dimension reduction? Maybe!

```


```{r}

## Creating preprocessing recipe

nba_train <- nba_train %>%
  mutate(across(
    is.character,
    as.factor
  ))

nba_ts_recipe <- 
  recipe(next_season_ts ~ ., data = nba_train) %>% 
  update_role(name_player, new_role = "id_variable") %>% 
  step_rm(contains("slug"), contains("url")) %>%
  step_dummy(all_nominal(), -has_role("id_variable")) %>% 
  step_knnimpute(all_numeric(),-all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_BoxCox(all_numeric(), -all_outcomes()) %>% 
  step_nzv(all_predictors(), -all_outcomes()) %>% 
  step_pca(all_numeric(), -all_outcomes(), threshold = 0.99)

summary(nba_ts_recipe)

## Creating model

lm_mod <- linear_reg() %>% 
  set_engine("lm")

## Put model and recipe into a workflow

nba_ts_wf <-
  workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(nba_ts_recipe)


```

```{r}

set.seed(33)
folds_nba_ts <- vfold_cv(nba_train, v = 10, repeats = 5, strata = next_season_ts)

keep_pred <- control_resamples(save_pred = T)

tic()
set.seed(33)
nba_ts_rs <-
  nba_ts_wf %>% 
  fit_resamples(folds_nba_ts, control = keep_pred)
toc()

nba_ts_rs %>% 
  collect_metrics(summarize = T)

```


